@startuml GestureGPT Architecture
!includeurl https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml

LAYOUT_WITH_LEGEND()

Person(user, "User", "Requests sign language video responses")

System_Boundary(gesturegpt, "GestureGPT") {
  Container(api, "GestureGPT API", "FastAPI", "OpenAI-compatible endpoints\n- Text to ASL conversion\n- Video stitching\n- Response formatting")

  ContainerDb(video_repo, "ASL Video Repository", "File System", "Pre-recorded sign videos\n- Individual signs (MP4)\n- Fingerspelling alphabet\n- Common phrases")
}

System_Ext(llm, "LLM Server", "Generates ASL-friendly text responses\n(OpenAI / Claude / Ollama / LM Studio)")

' Main flow
Rel(user, api, "POST /v1/chat/completions\n{messages: [...], format: 'mp4'}")
Rel(api, llm, "Generate text response")
Rel(llm, api, "ASL-friendly text\n'Hello! I feel good.'")
Rel(api, video_repo, "Lookup & stitch videos\n['HELLO', 'I', 'FEEL', 'GOOD']")
Rel(video_repo, api, "Video files")
Rel(api, user, "JSON + video URL\n/videos/response_abc123.mp4")

note right of api
  **Processing Flow:**
  1. Receive user message
  2. Get LLM text response
  3. Convert to ASL glosses
  4. Lookup videos from repo
  5. Stitch videos together
  6. Return video URL
end note

note right of video_repo
  **Dataset Structure:**
  datasets/
  ├── signs/
  │   ├── HELLO.mp4
  │   ├── GOOD.mp4
  │   └── ...
  └── fingerspell/
      ├── A.mp4
      └── ...
end note

@enduml
